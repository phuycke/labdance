% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/netinputs.R
\name{netinputs}
\alias{netinputs}
\title{netinputs}
\usage{
netinputs(beta)
}
\arguments{
\item{beta}{The learning rate. Influences the change in model weights. Since
the netinput is the dot product of the input activation and the weights,
beta has a direct impact of the level of activation at the output units.}

\item{wr}{Represents the weight resets that take place in our dynamic model.
This vector is a vector consisting of N binary values (0, 1), indicating
whether a weight reset at trial N has taken place. Hence, if a weight reset
takes place at trial 8, the first 8 elements of wr consist of 7 0's
followed by a single 1. This weight reset is needed to allows multiple
'learning events' to take place. More (but not too many!) events will
lead to a better recovery of beta.}
}
\value{
list consisting of M elements (the number of output units), where each
    subset consists of N elements (the number of trials).
}
\description{
Generates how the netinputs at the output level of a dynamic
    model evolve over time as a function of the learning rate beta and
    the weight resets. Since our dynamic model has two output units, netinput
    has N times 2 values, where N denotes the number of trials.
}
\examples{
ni = netinputs(beta = 0.5,
wr = rep(c(rep(0, times = 31), 1),
         times = 16))
rbind(ni[[1]][1:8], ni[[1]][1:8])

#      [,1] [,2] [,3] [,4]      [,5]      [,6]      [,7]      [,8]
# [1,]  0.5  0.5  0.5  0.5 0.5621765 0.5621765 0.4378235 0.4378235
# [2,]  0.5  0.5  0.5  0.5 0.5621765 0.5621765 0.4378235 0.4378235

}
