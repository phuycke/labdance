# d(n)LBA
return(simulate.dynamic(true_pars, sigma_gen))
}
}
netinputs <- function(beta, wr){
stim = diag(4)
t    = matrix(c(1, 1, 0, 0, 0, 0, 1, 1),
nrow = 4)
w    = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
# data holder
df      = matrix(0,
nrow = 512,
ncol = 2)
trials  = rep(1:4,
times = 512 / 4)
# simulate
for (i in 1:length(trials)){
s = trials[i]
# input at output units, logistic activation function
netinput = 1 / (1 + exp(-(stim[s,] %*% w)))
stopifnot(round(sum(netinput), 10) == 1)
# weight update
A = matrix(stim[s,])
B = (t[s, ] - netinput)
w = w + beta * (A %*% B)
# save the netinputs (used during estimation of LR)
df[i,1:2] = netinput
# reset the weights based on random draw
if (wr[i] == 1){
w = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
}
}
return(list(df[,1], df[,2]))
}
negloglik.behavioral <- function(to_optim, rt, response, conditions = NULL, wr = NULL) {
# at least one of the two must be NULL
stopifnot((!is.null(conditions) & is.null(wr)) | (is.null(conditions) & !is.null(wr)))
if (is.null(conditions)){
conditions = 1
}
# summed loglik
sum_ll = 0
for (i in seq_along(unique(conditions))){
# assign parameters to variable names
if (is.null(wr)){
par = c(A       = to_optim[["a"]],
b       = to_optim[["b"]],
t0      = to_optim[["t0"]],
mean_v1 = to_optim[[grep(sprintf("v_%d", i), names(to_optim))]],
mean_v2 = 1-to_optim[[grep(sprintf("v_%d", i), names(to_optim))]],
sd_v2   = to_optim[["sd"]])
} else{
par = c(A       = to_optim[["a"]],
b       = to_optim[["b"]],
t0      = to_optim[["t0"]],
mean_v1 = F,
mean_v2 = F,
sd_v2   = to_optim[["sd"]])
}
spar = par[!grepl("[12]$", names(par))]
# distribution parameters
dist_par_names  = unique(sub("[12]$", "", grep("[12]$", names(par), value = TRUE)))
dist_par        = vector("list",
length = length(dist_par_names))
names(dist_par) = dist_par_names
for (j in dist_par_names){
dist_par[[j]] = as.list(unname(par[grep(j, names(par))]))
}
# set common sd's
dist_par$sd_v = c(dist_par$sd_v, dist_par$sd_v)
if (!is.null(wr)){
# compute netinputs based on the fed in learning rate, and use this as drift rates
dist_par$mean_v = netinputs(beta = to_optim[[grep("beta", names(to_optim))]],
wr   = wr)
}
# get summed log-likelihood
if (length(conditions) == 1){
react = list(rt)
resp  = list(response)
} else{
react = list(rt[conditions == i])
resp  = list(response[conditions == i])
}
d = do.call(dLBA, args = c(rt           = react,
response     = resp,
spar,
dist_par,
distribution = "norm",
silent       = TRUE))
# get -loglik for this subsection of the data
if (any(d < 0e-10)){
ll = 1e6
}
else{
ll = -sum(log(d))
}
sum_ll = sum_ll + ll
}
return(sum_ll)
}
likelihood.neural <- function(to_optim, neural_data, conditions = NULL, netinput = NULL){
stopifnot((!is.null(conditions) & is.null(netinput)) | (is.null(conditions) & !is.null(netinput)))
if (!is.null(conditions)){
# for nLBA
sum_ll = 0
for (i in seq_along(unique(conditions))){
sum_ll = sum_ll + sum((neural_data[conditions == i] - to_optim[[grep(sprintf("v_%d", i), names(to_optim))]])^2)
}
return(sum_ll)
} else{
# for dnLBA
return(sum((neural_data - netinput)^2))
}
}
likelihood.summed <- function(to_optim, rt, response, neural_data = NULL, conditions = NULL, wr = NULL,
netinput = NULL, sigma_mod = NULL){
ll.behavioral = negloglik.behavioral(to_optim, rt, response, conditions, wr)
# for non neural data, only return the behavioral loglikelihood
if (is.null(neural_data)){
return(ll.behavioral)
} else{
# for neural data, return the sum of both
ll.neural = likelihood.neural(to_optim, neural_data, conditions, netinput)
return(ll.behavioral + (1/(2*(sigma_mod)^2)) * ll.neural)
}
}
recovery <- function(base_par, df, cycles, sigma_gen = NULL, sigma_mod = NULL){
# determine the type of data
if ("beta" %in% base_par){
dynamic = T
n_drift = NULL
} else{
dynamic = F
n_drift = length(unique(df$repetition))
}
# actual parameter recovery
for (q in 1:cycles){
o = tryCatch(optim(param.draw(base_par = base_par,                     # initial parameter guess
n_drift  = n_drift,
dynamic  = dynamic),
likelihood.summed,                                  # goal function to optimize
method        = "L-BFGS-B",                         # minimization method
rt            = df$rt,
response      = df$response,
conditions    = df$repetition,
wr            = df$weight_reset,
neural_dat    = df$neural,
netinput      = df$mean_v1,
sigma_mod     = sigma_mod,
lower         = rep(0, times = length(start)),      # parameter lower bound
upper         = rep(Inf, times = length(start)),    # parameter upper bound
control       = list(maxit = 5000),
hessian       = TRUE),
error = function(e){NA})
# if o is not NA, AND if converged, AND if the LR estimate != 0 --> break
if (length(o) > 1){
if(o$convergence == 0){
if(!any(o$par < 0.0001)){
break
}
}
}
}
if (length(o) == 1){
return(rep(NA, times = length(start) + 2))
} else{
# save the lowest value of the eigen values of the Hessian
# all should be positive (> epsilon, with epsilon = 0.01) when minimizing
h = min(eigen(o$hessian)$values)
return(c(o$par, o$value, h))
}
}
# test on experimental data ----
require(dplyr)
# read data
setwd("C:/Users/pieter/Downloads/GitHub/phuycke/alpha_theta_timescales/2. Data preparation/Resulting data")
df = read.csv("theta_alpha_beta_behavioural.csv")
# test case for one subject
d = df %>% filter(Subject_nr == 2 & Condition == "Novel") %>%
mutate(response = case_when(Response == "Left" ~ 1,
Response == "Right" ~ 2),
rt = RT / 1000) %>%
rename(sub_id = Subject_nr,
repetition = Repetitions_block,
block = Block_specific,
trialnum = Trial_block) %>%
select(sub_id, rt, response, block, trialnum)
# weight resets
w = c()
for (i in unique(d$block)){
l = nrow(d[d$block == i, ]) - 1
w = c(w, c(rep(0, times = l), 1))
}
d$weight_reset = w
View(d)
beta=.5
stim = diag(4)
t    = matrix(c(1, 1, 0, 0, 0, 0, 1, 1),
nrow = 4)
w    = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
# data holder
df      = matrix(0,
nrow = 256,
ncol = 4)
# add block number and trial number
df[,1]  = rep(1:8, each = 16)
df[,2]  = rep(1:32, times = 8)
trials  = rep(1:4,
times = 256 / 4)
wr = rep(c(rep(0, times = 31), 1), times = 8)
# simulate
for (i in 1:length(trials)){
s = trials[i]
# input at output units, logistic activation function
netinput = 1 / (1 + exp(-(stim[s,] %*% w)))
stopifnot(round(sum(netinput), 10) == 1)
# weight update
A = matrix(stim[s,])
B = (t[s, ] - netinput)
w = w + beta * (A %*% B)
# save the netinputs (used during estimation of LR)
df[i,3:4] = netinput
# reset the weights based on random draw
if (wr[i] == 1){
w = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
}
}
df
stim = diag(4)
t    = matrix(c(1, 1, 0, 0, 0, 0, 1, 1),
nrow = 4)
w    = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
# data holder
df      = matrix(0,
nrow = 256,
ncol = 4)
# add block number and trial number
df[,1]  = rep(1:8, each = 32)
df[,2]  = rep(1:32, times = 8)
trials  = rep(1:4,
times = 256 / 4)
wr = rep(c(rep(0, times = 31), 1), times = 8)
# simulate
for (i in 1:length(trials)){
s = trials[i]
# input at output units, logistic activation function
netinput = 1 / (1 + exp(-(stim[s,] %*% w)))
stopifnot(round(sum(netinput), 10) == 1)
# weight update
A = matrix(stim[s,])
B = (t[s, ] - netinput)
w = w + beta * (A %*% B)
# save the netinputs (used during estimation of LR)
df[i,3:4] = netinput
# reset the weights based on random draw
if (wr[i] == 1){
w = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
}
}
View(df)
View(d)
head(df)
df = data.frame(df)
View(df)
colnames(df) = c("block", "trialnum", "mean_v1", "mean_v2")
df %>% filter((block == d$block) & trialnum == d$trialnum))
df %>% filter(block == d$block & trialnum == d$trialnum)
d$trialnum
df %>% filter(block == 1  %>% (trialnum == d$trialnum)
)
df %>% filter(block == 1)
df %>% filter(block == 1)  %>% (trialnum == d$trialnum)
df %>% filter(block == 1)  %>% filter(trialnum == d$trialnum)
i = 1
temp = d[d$block == i, ]
temp
rep(1:8, each = 4
)
8*32
# add block number and trial number
df[,1]  = rep(1:8, each = 32)
rep(1:32, times = 8)
stim = diag(4)
t    = matrix(c(1, 1, 0, 0, 0, 0, 1, 1),
nrow = 4)
w    = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
# data holder
df      = matrix(0,
nrow = 256,
ncol = 4)
# add block number and trial number
df[,1]  = rep(1:8, each = 32)
df[,2]  = rep(1:32, times = 8)
trials  = rep(1:4,
times = 256 / 4)
wr = rep(c(rep(0, times = 31), 1), times = 8)
# simulate
for (i in 1:length(trials)){
s = trials[i]
# input at output units, logistic activation function
netinput = 1 / (1 + exp(-(stim[s,] %*% w)))
stopifnot(round(sum(netinput), 10) == 1)
# weight update
A = matrix(stim[s,])
B = (t[s, ] - netinput)
w = w + beta * (A %*% B)
# save the netinputs (used during estimation of LR)
df[i,3:4] = netinput
# reset the weights based on random draw
if (wr[i] == 1){
w = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
}
}
View(df)
netinputs <- function(beta){
stim = diag(4)
t    = matrix(c(1, 1, 0, 0, 0, 0, 1, 1),
nrow = 4)
w    = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
# data holder
df      = matrix(0,
nrow = 256,
ncol = 4)
# add block number and trial number
df[,1]  = rep(1:8, each = 32)
df[,2]  = rep(1:32, times = 8)
trials  = rep(1:4,
times = 256 / 4)
wr = rep(c(rep(0, times = 31), 1), times = 8)
# simulate
for (i in 1:length(trials)){
s = trials[i]
# input at output units, logistic activation function
netinput = 1 / (1 + exp(-(stim[s,] %*% w)))
stopifnot(round(sum(netinput), 10) == 1)
# weight update
A = matrix(stim[s,])
B = (t[s, ] - netinput)
w = w + beta * (A %*% B)
# save the netinputs (used during estimation of LR)
df[i,3:4] = netinput
# reset the weights based on random draw
if (wr[i] == 1){
w = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
}
}
return(list(df[,1], df[,2]))
}
# load reticulate and use it to load numpy
library(reticulate)
np <- import("numpy")
# data reading
mat <- np$load("M:\shares\pp02_labverguts\Pieter Huycke\Study 1\2. Behavioral data\Raw\Experiment\sub-02.npy")
rm(list = ls())
rm(list = ls())
netinputs <- function(beta){
stim = diag(4)
t    = matrix(c(1, 1, 0, 0, 0, 0, 1, 1),
nrow = 4)
w    = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
# data holder
df      = matrix(0,
nrow = 256,
ncol = 4)
# add block number and trial number
df[,1]  = rep(1:8, each = 32)
df[,2]  = rep(1:32, times = 8)
trials  = rep(1:4,
times = 256 / 4)
wr = rep(c(rep(0, times = 31), 1), times = 8)
# simulate
for (i in 1:length(trials)){
s = trials[i]
# input at output units, logistic activation function
netinput = 1 / (1 + exp(-(stim[s,] %*% w)))
stopifnot(round(sum(netinput), 10) == 1)
# weight update
A = matrix(stim[s,])
B = (t[s, ] - netinput)
w = w + beta * (A %*% B)
# save the netinputs (used during estimation of LR)
df[i,3:4] = netinput
# reset the weights based on random draw
if (wr[i] == 1){
w = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
}
}
return(list(df[,1], df[,2]))
}
# load reticulate and use it to load numpy
library(reticulate)
np <- import("numpy")
# data reading
subject1 <- np$load("M:/shares/pp02_labverguts/Pieter Huycke/Study 1/2. Behavioral data/Raw/Experiment/sub-02.npy")
subject1
rm(list = ls())
netinputs <- function(beta){
stim = diag(4)
t    = matrix(c(1, 1, 0, 0, 0, 0, 1, 1),
nrow = 4)
w    = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
# data holder
df      = matrix(0,
nrow = 256,
ncol = 4)
# add block number and trial number
df[,1]  = rep(1:8, each = 32)
df[,2]  = rep(1:32, times = 8)
trials  = rep(1:4,
times = 256 / 4)
wr = rep(c(rep(0, times = 31), 1), times = 8)
# simulate
for (i in 1:length(trials)){
s = trials[i]
# input at output units, logistic activation function
netinput = 1 / (1 + exp(-(stim[s,] %*% w)))
stopifnot(round(sum(netinput), 10) == 1)
# weight update
A = matrix(stim[s,])
B = (t[s, ] - netinput)
w = w + beta * (A %*% B)
# save the netinputs (used during estimation of LR)
df[i,3:4] = netinput
# reset the weights based on random draw
if (wr[i] == 1){
w = matrix(0,
nrow = nrow(stim),
ncol = ncol(t))
}
}
return(list(df[,1], df[,2]))
}
# testing ----
library(reticulate)
np = import("numpy")
s1 = np$load("M:/shares/pp02_labverguts/Pieter Huycke/Study 1/2. Behavioral data/Raw/Experiment/sub-02.npy")
s1 = data.frame(s1)
head(s1)
View(s1)
colnames(s1) = c("stim", "repetition", "condition", "target", "response", "accuracy", "rt")
head(s1)
s %>% filter(condition == 1)
s = s1 %>% filter(condition == 1)
View(s)
s = s1 %>% mutate(condition = case_when(condition == 0 ~ "novel",
condition == 1 ~ "repeating"))
View(s)
s = s1 %>% mutate(condition = case_when(condition == 0 ~ "novel",
condition == 1 ~ "repeating"),
target = target + 1,
response = response + 1)
View(s)
s = s1 %>% mutate(condition = case_when(condition == 0 ~ "novel",
condition == 1 ~ "repeating"),
target = target + 1,
response = response + 1,
rt = rt / 1000)
View(s)
s = s1 %>% mutate(condition = case_when(condition == 0 ~ "novel",
condition == 1 ~ "repeating"),
target = target + 1,
response = response + 1,
rt = rt / 1000) %>%
filter(condition == "novel")
View(s)
View(s)
s$block = rep(1:32, times = 8)
s$block    = rep(1:16, each = 32)
s$block    = rep(1:16, each = 16)
s$trialnum = rep(1:32, times = 8)
s$block    = rep(1:16, each = 16)
View(s)
s$block    = rep(1:8, each = 32)
View(s)
temp = s[s$block == 1, ]
temp
unique(temp$stim)
sort(unique(temp$stim))
stimuli = sort(unique(temp$stim))
?wher
?where
where(stimuli == 9)
tidyselect::::where(stimuli == 9)
tidyselect::where(stimuli == 9)
stimuli == 9
which(stimuli == 9)
